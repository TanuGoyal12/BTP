{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3df7a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.8/site-packages (0.4.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from evaluate) (2022.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from evaluate) (1.22.4)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.8/site-packages (from evaluate) (0.3.5.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.8/site-packages (from evaluate) (4.64.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from evaluate) (3.0.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from evaluate) (2.5.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from evaluate) (0.70.13)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from evaluate) (0.9.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from evaluate) (1.4.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from evaluate) (2.27.1)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.8/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (7.0.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.3.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->evaluate) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (1.26.9)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (21.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->evaluate) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b18dd2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import Adafactor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "034aa28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "597041a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import Set, List\n",
    "import re\n",
    "\n",
    "\n",
    "class KB:\n",
    "    def __init__(self, kb_path: str):\n",
    "        self.kb_path = kb_path\n",
    "        self.entities, self.relations, self.triplets = self.load_kb()\n",
    "\n",
    "    def load_kb(self) -> (Set[str], Set[str], List[List[str]]):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class MetaQAKB(KB):\n",
    "    SPECIAL_CHAR = 'SPC'\n",
    "\n",
    "    def __init__(self, kb_path: str, add_reverse_rel: bool = True):\n",
    "        self.add_reverse_rel = add_reverse_rel\n",
    "        # self.regex = re.compile(\"[^a-zA-Z0-9\\\\s*.!?',_\\\\-]\")\n",
    "        super().__init__(kb_path)\n",
    "\n",
    "    # def normalize_chars(self, strl: List[str]) -> List[str]:\n",
    "    #     return [self.regex.sub(self.SPECIAL_CHAR, x) for x in strl]\n",
    "\n",
    "    def load_kb(self) -> (Set, Set, List):\n",
    "        \"\"\"\n",
    "        Loads the knowledge base from the given path\n",
    "        :return: set of entities, set of relations, list of triplets\n",
    "        \"\"\"\n",
    "        entities = set()\n",
    "        relations = set()\n",
    "        triplets = []\n",
    "\n",
    "        with open(self.kb_path, 'r') as f:\n",
    "            lines = f.read().strip().split('\\n')\n",
    "            for line in tqdm(lines):\n",
    "                triplet = line.split('|')\n",
    "                # e1, e2 = self.normalize_chars([triplet[0], triplet[2]])\n",
    "                e1, e2 = triplet[0], triplet[2]\n",
    "                r = triplet[1]\n",
    "\n",
    "                triplets.append([e1, r, e2])\n",
    "                if self.add_reverse_rel:\n",
    "                    rel = r + '_reverse'\n",
    "                    triplets.append([e2, rel, e1])\n",
    "                    relations.add(rel)\n",
    "\n",
    "                entities.add(e1)\n",
    "                entities.add(e2)\n",
    "                relations.add(r)\n",
    "\n",
    "        print(f\"loaded {len(triplets)} triplets with {len(entities)} entities and {len(relations)} relations\")\n",
    "        return entities, relations, triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e1f343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "# from knowledge_handler.prolog import PrologDA\n",
    "# from knowledge_handler.kb import MetaQAKB\n",
    "import random\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "class MetaQADataLoader:\n",
    "    def __init__(self, base_path, split='test'):\n",
    "        self.base_path = base_path\n",
    "#         self.prolog_da = PrologDA()\n",
    "\n",
    "        kb_path = os.path.join(base_path, 'kb.txt')\n",
    "#         self.kb = MetaQAKB(kb_path)\n",
    "\n",
    "#         self.prolog_da.register_kb(self.kb)\n",
    "        self.dataset = self.load_question_answers(base_path, split)\n",
    "\n",
    "    def load_question_answers(self, base_path, split='test') -> Dict:\n",
    "        multi_hop_paths = ['1hop', '2hop', '3hop']\n",
    "        dataset = {}\n",
    "\n",
    "        for multi_hop_path in multi_hop_paths:\n",
    "            hop_path = os.path.join(base_path, multi_hop_path)\n",
    "\n",
    "            questions_path = os.path.join(hop_path, f'qa_{split}.txt')\n",
    "            questions = []\n",
    "            answers = []\n",
    "            question_concepts = []\n",
    "\n",
    "            with open(questions_path, 'r') as f:\n",
    "                lines = f.read().strip().split('\\n')\n",
    "                for line in lines:\n",
    "                    q, a = line.split('\\t')\n",
    "                    question_concept = re.findall(r'\\[(.+)\\]', q)[0]\n",
    "                    # question_concept_cleaned = self.kb.regex.sub(self.kb.SPECIAL_CHAR, question_concept)\n",
    "#                     q = q.replace(question_concept, 'ENT')\n",
    "                    question_concepts.append(question_concept)\n",
    "                    q = q.replace(\"[\", \"\", 1)\n",
    "                    q = q.replace(\"]\", \"\", 1)\n",
    "                    if split == \"train\":\n",
    "                        num_pos_ans = len(a.split('|'))\n",
    "                        questions.extend([q]*num_pos_ans)\n",
    "                        answers.extend(a.split('|'))\n",
    "                    else:\n",
    "                        questions.append(q)\n",
    "                        answers.append(a.split('|'))\n",
    "            df = pd.DataFrame(list(zip(questions, answers)), columns =['question', 'answer'])\n",
    "                \n",
    "\n",
    "#             dataset[multi_hop_path] = list(zip(questions, answers, question_concepts))\n",
    "            dataset[multi_hop_path] = df\n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dc540e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = MetaQADataLoader(\"/workspace/tanu/BTP-2/exp/knowledge infusion/metaqa/\", \"test\")\n",
    "train_data_loader = MetaQADataLoader(\"/workspace/tanu/BTP-2/exp/knowledge infusion/metaqa/\", \"train\")\n",
    "dev_data_loader = MetaQADataLoader(\"/workspace/tanu/BTP-2/exp/knowledge infusion/metaqa/\", \"dev\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c5b1266",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop = \"2hop\"\n",
    "test_data = test_data_loader.dataset[hop]\n",
    "train_data = train_data_loader.dataset[hop]\n",
    "dev_data = dev_data_loader.dataset[hop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc8adee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>which person directed the movies starred by Jo...</td>\n",
       "      <td>[Nancy Meyers, Sam Mendes, George Clooney, Ken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>who are movie co-directors of Delbert Mann</td>\n",
       "      <td>[Franco Zeffirelli, Cary Fukunaga, Lewis Miles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what are the primary languages in the movies d...</td>\n",
       "      <td>[German]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the screenwriter Mimsy Farmer co-wrote movies ...</td>\n",
       "      <td>[Barbet Schroeder]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  which person directed the movies starred by Jo...   \n",
       "1         who are movie co-directors of Delbert Mann   \n",
       "2  what are the primary languages in the movies d...   \n",
       "3  the screenwriter Mimsy Farmer co-wrote movies ...   \n",
       "\n",
       "                                              answer  \n",
       "0  [Nancy Meyers, Sam Mendes, George Clooney, Ken...  \n",
       "1  [Franco Zeffirelli, Cary Fukunaga, Lewis Miles...  \n",
       "2                                           [German]  \n",
       "3                                 [Barbet Schroeder]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_loader.dataset[hop][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41b27c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "739782"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87498407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>which person wrote the films directed by Yuriy...</td>\n",
       "      <td>Sergei Kozlov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>which movies have the same director of Just Cause</td>\n",
       "      <td>The Mambo Kings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what genres do the movies written by Maureen M...</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what were the release years of the movies acte...</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what were the release years of the movies acte...</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>what are the movies that have the same screenw...</td>\n",
       "      <td>Gone with the Wind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>what are the movies that have the same screenw...</td>\n",
       "      <td>Raffles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>what are the movies that have the same screenw...</td>\n",
       "      <td>Elmer Gantry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>what are the movies that have the same screenw...</td>\n",
       "      <td>Cass Timberlane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>what are the movies that have the same screenw...</td>\n",
       "      <td>Arrowsmith</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question              answer\n",
       "0  which person wrote the films directed by Yuriy...       Sergei Kozlov\n",
       "1  which movies have the same director of Just Cause     The Mambo Kings\n",
       "2  what genres do the movies written by Maureen M...               Drama\n",
       "3  what were the release years of the movies acte...                1998\n",
       "4  what were the release years of the movies acte...                1993\n",
       "5  what are the movies that have the same screenw...  Gone with the Wind\n",
       "6  what are the movies that have the same screenw...             Raffles\n",
       "7  what are the movies that have the same screenw...        Elmer Gantry\n",
       "8  what are the movies that have the same screenw...     Cass Timberlane\n",
       "9  what are the movies that have the same screenw...          Arrowsmith"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_loader.dataset[hop][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff3c36bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what are the languages spoken in the films dir...</td>\n",
       "      <td>[Greek]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the films acted by Sharon Tate were released i...</td>\n",
       "      <td>[1967, 1968]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>when did the films written by Anthony Mann rel...</td>\n",
       "      <td>[1949, 1947]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what genres do the movies directed by Clark Gr...</td>\n",
       "      <td>[Drama, Comedy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when did the movies written by Emir Kusturica ...</td>\n",
       "      <td>[1998, 1995, 2007, 1988, 1981]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  what are the languages spoken in the films dir...   \n",
       "1  the films acted by Sharon Tate were released i...   \n",
       "2  when did the films written by Anthony Mann rel...   \n",
       "3  what genres do the movies directed by Clark Gr...   \n",
       "4  when did the movies written by Emir Kusturica ...   \n",
       "\n",
       "                           answer  \n",
       "0                         [Greek]  \n",
       "1                    [1967, 1968]  \n",
       "2                    [1949, 1947]  \n",
       "3                 [Drama, Comedy]  \n",
       "4  [1998, 1995, 2007, 1988, 1981]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ada8679c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what were the release years of the movies acted by Todd Field'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_loader.dataset[hop].iloc[4][\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0d1dbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(row):\n",
    "    return \"Question: {} Answer: <extra_id_0>\".format(row[\"question\"])\n",
    "def get_label(row):\n",
    "    return \"<extra_id_0> {}.\".format(row[\"answer\"])\n",
    "def get_eval_label(row):\n",
    "    return [\"<extra_id_0> {}.\".format(r) for r in row[\"answer\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6d684d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"input\"] = train_data.apply(prompt, axis = 1)\n",
    "train_data[\"label\"] = train_data.apply(get_label, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9c974d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data[\"input\"] = dev_data.apply(prompt, axis = 1)\n",
    "dev_data[\"label\"] = dev_data.apply(get_eval_label, axis = 1)\n",
    "test_data[\"input\"] = test_data.apply(prompt, axis = 1)\n",
    "test_data[\"label\"] = test_data.apply(get_eval_label, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "006a38a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question    what are the primary languages in the movies d...\n",
       "answer                                               [German]\n",
       "input       Question: what are the primary languages in th...\n",
       "label                                  [<extra_id_0> German.]\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "744433e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def em_metric(preds, refs):\n",
    "#     total = len(refs)  #TODO: should it be preds instead\n",
    "#     correct = set(preds).intersection(set(refs))\n",
    "#     return correct/total\n",
    "\n",
    "# def em_metric(preds, refs):\n",
    "#     total  =  0.0\n",
    "#     for pred,ref in zip(preds,refs):\n",
    "#         if pred in ref:\n",
    "#             total += 1/len(ref)\n",
    "#     return total/len(preds)\n",
    "\n",
    "def em_metric(preds, refs):\n",
    "    total  =  0.0\n",
    "    for pred,ref in zip(preds,refs):\n",
    "        if pred in ref:\n",
    "            total += 1\n",
    "    return total/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "405e5f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "input    Question: which person wrote the films directe...\n",
       "label                          <extra_id_0> Sergei Kozlov.\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[0][[\"input\", \"label\"]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5e74d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:164: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-large\")\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"/workspace/tanu/BTP-2/exp/knowledge infusion/trained models/KGinfusedLM/6\") \n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"t5-large\") \n",
    "# workspace/tanu/aviation/trained models/KGinfusedLM_ankush_c4/20\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"/workspace/tanu/aviation/trained models/KGinfusedLM_ankush_c4/20\") \n",
    "\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"/workspace/tanu/trained models/metaqa-finetuned-using-KGLM20/2hop/9\") \n",
    "# # model = T5ForConditionalGeneration.from_pretrained(\"/workspace/tanu/trained models/metaqa-finetuned-using-KGLM20/1hop/1\") \n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"/workspace/tanu/trained models/metaqa-finetuned-using-KGLM20/1hop/9\") \n",
    "\n",
    "# tanu/BTP-2/exp/knowledge infusion/trained models/KGinfusedLM/19\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"/workspace/tanu/trained models/metaqa-finetuned/1hop/9\") \n",
    "\n",
    "#replace with the trained model dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38f462f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return tokenizer(text, return_tensors=\"pt\",  padding=True, truncation=True)\n",
    "def tokenize_target(text):\n",
    "    return tokenizer(text, return_tensors=\"pt\",   padding=True, truncation=True).input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6dbb31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fd17baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adafactor(model.parameters(), lr=1e-3, relative_step = False)\n",
    "num_epochs = 20  #TODO : unspecified num epochs for finetuning\n",
    "batch_size = 16\n",
    "num_training_steps = num_epochs * (train_data.shape[0] // batch_size )\n",
    "# lr_scheduler = get_scheduler(\n",
    "#     \"linear\",\n",
    "#     optimizer=optimizer,\n",
    "#     num_warmup_steps=0,\n",
    "#     num_training_steps=num_training_steps,\n",
    "# )\n",
    "# Adafactor(model.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7362d775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8962aebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f45dc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e3ccae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P = []\n",
    "# R = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adb86c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_data(model, data, batch_size, optimizer, tokenizer, device, eval_mode):\n",
    "    iters = int(np.ceil(data.shape[0] / batch_size))\n",
    "    avg_loss = 0\n",
    "    step = 0\n",
    "    p_bar = tqdm(total=iters, position=0, leave=True, desc='Running through data')\n",
    "    for row_idx in range(0, data.shape[0], batch_size):\n",
    "        upper_idx = min(row_idx + batch_size, data.shape[0]) -1\n",
    "#         upper_idx =\n",
    "        labels = data.loc[row_idx : upper_idx]['label'].tolist()\n",
    "        inputs = data.loc[row_idx : upper_idx]['input'].tolist()\n",
    "        tokenized_input = tokenize(inputs)\n",
    "#         global input_ids \n",
    "#         global attention_mask\n",
    "        input_ids = tokenized_input[\"input_ids\"].to(device)\n",
    "        attention_mask = tokenized_input[\"attention_mask\"].to(device)\n",
    "       \n",
    "        if not eval_mode:\n",
    "            tokenized_labels = tokenize_target(labels)\n",
    "            labels = tokenized_labels.to(device)\n",
    "            labels[labels == tokenizer.pad_token_id] = -100\n",
    "#             labels[labels == 32099] = -100\n",
    "#             labels[labels == 32098] = -100\n",
    "            loss = model(input_ids= input_ids, attention_mask= attention_mask,labels= labels).loss\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                sequence_ids = model.generate(input_ids = input_ids, attention_mask= attention_mask)\n",
    "                pred = tokenizer.batch_decode(sequence_ids)\n",
    "                labels = [[re.sub(\"[\\<\\[].*?[\\>\\]]\", \"\", x).strip()  for x in label] for label in  labels]\n",
    "                pred = [re.sub(\"[\\<\\[].*?[\\>\\]]\", \"\", x).strip() for x in pred]\n",
    "                \n",
    "#                 P.extend(pred)\n",
    "#                 R.extend(labels)\n",
    "                loss_item = em_metric(pred,labels)\n",
    "\n",
    "        if not eval_mode:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_item = loss.detach().clone().item()\n",
    "\n",
    "#             lr_scheduler.step()\n",
    "        \n",
    "#         loss_item = loss.detach().clone().item()\n",
    "#         print(loss_item)\n",
    "#         return\n",
    "        avg_loss = (avg_loss * step + loss_item) / (step + 1)\n",
    "\n",
    "        p_bar.set_postfix(avg_loss=avg_loss)\n",
    "        p_bar.update(1)\n",
    "        step += 1\n",
    "\n",
    "    p_bar.close()\n",
    "    return model, optimizer, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a414b09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: what are the languages spoken in the films directed by Joel Zwick Answer: <extra_id_0>'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data.iloc[0][\"input\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acd1a1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA A100-SXM4-80GB'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30a17b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2hop'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9db8d396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through data:   0%|                                                                                                                                                                | 0/930 [00:00<?, ?it/s]/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:1202: UserWarning: Neither `max_length` nor `max_new_tokens` have been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Running through data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 930/930 [03:32<00:00,  4.37it/s, avg_loss=0.0185]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "_, _, avg_eval_loss = run_data(model, dev_data, batch_size, \\\n",
    "                                optimizer, tokenizer, device, eval_mode=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43b87730",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'P' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mP\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m x\n",
      "\u001b[0;31mNameError\u001b[0m: name 'P' is not defined"
     ]
    }
   ],
   "source": [
    "x = P[0][0]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4c6865",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(\"[\\<\\[].*?[\\>\\]]\", \"\", x).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c0b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "P[0][:10], R[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b0b112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c9bf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099a9564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 930/930 [03:35<00:00,  4.31it/s, avg_loss=0.0185]\n",
      "Running through data:   2%|██▊                                                                                                                               | 1012/46237 [07:51<5:37:38,  2.23it/s, avg_loss=2.69]"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "eval_losses = []\n",
    "model.eval()\n",
    "_, _, avg_eval_loss = run_data(model, dev_data, batch_size, \\\n",
    "                                optimizer, tokenizer, device, eval_mode=True)\n",
    "# print(avg_eval_loss)        \n",
    "for epoch in range(10,num_epochs):\n",
    "        shuffled_train_data = train_data.sample(frac=1).reset_index() \n",
    "        model.train()\n",
    "        optimizer.zero_grad() \n",
    "        model, optimizer, avg_train_loss = run_data(model, shuffled_train_data, batch_size, \\\n",
    "                                optimizer, tokenizer, device, eval_mode=False)\n",
    "        model.eval()\n",
    "        _, _, avg_eval_loss = run_data(model, dev_data, batch_size, \\\n",
    "                                optimizer, tokenizer, device, eval_mode=True)\n",
    "#         break\n",
    "        \n",
    "        train_losses.append(avg_train_loss)\n",
    "        eval_losses.append(avg_eval_loss)\n",
    "        print(f'Epoch {epoch}:\\tTrain loss: {avg_train_loss}\\t\\t Eval loss: {avg_eval_loss}')\n",
    "        model.save_pretrained(f\"trained models/metaqa-finetuned-using-C4_20/{hop}/{epoch}\", from_pt=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e50f5039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.11122311827956989], [1.552494299562091])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_losses, train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6784c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_losses, train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e22401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt [0], pred, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4874357",
   "metadata": {},
   "outputs": [],
   "source": [
    "exm = \"Question: the films acted by Shaun White were in which genres? Answer: <extra_id_0> \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de294fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "exm = \"Question: what movies did Temuera Morrison act in Answer: <extra_id_0>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cdd32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(exm , return_tensors=\"pt\").input_ids\n",
    "sequence_ids = model.generate(input_ids)\n",
    "sequences = tokenizer.batch_decode(sequence_ids)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd37b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "exact_match_metric = load(\"exact_match\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0d9e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8bac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [\"abc\"]\n",
    "references = [\"abc\"]\n",
    "results = exact_match_metric.compute(predictions=predictions, references=references)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
